
### Poisoning the training data 
-> To Confuse the AI
* Send modified training data that causes the AI to behave incorrectly


### Evasion attack



## Secure the learning algorithms
* Check the Training data
* Constantly review training data